png(filename=file.path(PSDS_PATH, 'figures', 'psds_0602.png'), width = 5.5, height=4, units='in', res=300)
ggplot(data=loan200_df, aes(x=payment_inc_ratio, dti, color=outcome, shape=outcome)) +
geom_point(size=2) +
scale_shape_manual(values = c(1, 4, 15)) +
geom_path(aes(x=x, y=y), color='black') +
xlim(3, 15) +
ylim(17, 29) +
theme_bw()
dev.off()
## Standardization
loan_df <- model.matrix(~ -1 + payment_inc_ratio + dti + revol_bal + revol_util, data=loan_data)
newloan = loan_df[1,, drop=FALSE]
loan_df = loan_df[-1,]
outcome <- loan_data[-1,1]
knn_pred <- knn(train=loan_df, test=newloan, cl=outcome, k=5)
knn_pred
loan_df[attr(knn_pred,"nn.index"),]
loan_df <- model.matrix(~ -1 + payment_inc_ratio + dti + revol_bal + revol_util, data=loan_data)
loan_std <- scale(loan_df)
target_std = loan_std[1,, drop=FALSE]
loan_std = loan_std[-1,]
outcome <- loan_data[-1,1]
knn_pred <- knn(train=loan_std, test=target_std, cl=outcome, k=5)
knn_pred
loan_df[attr(knn_pred,"nn.index"),]
## Create a feature for borrowers
borrow_df <- model.matrix(~ -1 + dti + revol_bal + revol_util + open_acc +
delinq_2yrs_zero + pub_rec_zero, data=loan_data)
borrow_knn <- knn(borrow_df, test=borrow_df, cl=loan_data[, 'outcome'], prob=TRUE, k=20)
prob <- attr(borrow_knn, "prob")
borrow_feature <- ifelse(borrow_knn=='default', 1-prob, prob)
summary(borrow_feature)
loan_data$borrower_score <- borrow_feature
# Decision trees
loan_tree <- rpart(outcome ~ borrower_score + payment_inc_ratio,
data=loan3000,
control = rpart.control(cp=.005))
## Figure 6-3: Rules for simple tree model (not same as in book)
png(filename=file.path(PSDS_PATH, 'figures', 'psds_rpart_tree.png'),  width = 6, height=4, units='in', res=300)
par(mar=c(0,0,0,0)+.1)
plot(loan_tree, uniform=TRUE, margin=.05)
text(loan_tree, cex=.75)
dev.off()
## Figure 6-4: View of partition rules
r_tree <- data_frame(x1 = c(0.575, 0.375, 0.375, 0.375, 0.475),
x2 = c(0.575, 0.375, 0.575, 0.575, 0.475),
y1 = c(0,         0, 10.42, 4.426, 4.426),
y2 = c(25,       25, 10.42, 4.426, 10.42),
rule_number = factor(c(1, 2, 3, 4, 5)))
r_tree <- as.data.frame(r_tree)
labs <- data.frame(x=c(.575 + (1-.575)/2,
.375/2,
(.375 + .575)/2,
(.375 + .575)/2,
(.475 + .575)/2,
(.375 + .475)/2
),
y=c(12.5,
12.5,
10.42 + (25-10.42)/2,
4.426/2,
4.426 + (10.42-4.426)/2,
4.426 + (10.42-4.426)/2
),
decision = factor(c('paid off', 'default', 'default', 'paid off', 'paid off', 'default')))
png(filename=file.path(PSDS_PATH, 'figures', 'psds_0604.png'), width = 6, height=4, units='in', res=300)
ggplot(data=loan3000, aes(x=borrower_score, y=payment_inc_ratio)) +
geom_point( aes(color=outcome, shape=outcome), alpha=.5) +
scale_color_manual(values=c('blue', 'red')) +
scale_shape_manual(values = c(1, 46)) +
# scale_shape_discrete(solid=FALSE) +
geom_segment(data=r_tree, aes(x=x1, y=y1, xend=x2, yend=y2, linetype=rule_number), size=1.5, alpha=.7) +
guides(colour = guide_legend(override.aes = list(size=1.5)),
linetype = guide_legend(keywidth=3, override.aes = list(size=1))) +
scale_x_continuous(expand=c(0,0)) +
scale_y_continuous(expand=c(0,0), limits=c(0, 25)) +
geom_label(data=labs, aes(x=x, y=y, label=decision)) +
#theme(legend.position='bottom') +
theme_bw()
dev.off()
## Gini coefficient and impurity
info <- function(x){
info <- ifelse(x==0, 0, -x * log2(x) - (1-x) * log2(1-x))
return(info)
}
x <- 0:50/100
plot(x, info(x) + info(1-x))
gini <- function(x){
return(x * (1-x))
}
plot(x, gini(x))
impure <- data.frame(p = rep(x, 3),
impurity = c(2*x,
gini(x)/gini(.5)*info(.5),
info(x)),
type = rep(c('Accuracy', 'Gini', 'Entropy'), rep(51,3)))
## Figure 06-05: comparison of impurity measures
png(filename=file.path(PSDS_PATH, 'figures', 'psds_0605.png'), width = 5, height=4, units='in', res=300)
ggplot(data=impure, aes(x=p, y=impurity, linetype=type, color=type)) +
geom_line(size=1.5) +
guides( linetype = guide_legend( keywidth=3, override.aes = list(size=1))) +
scale_x_continuous(expand=c(0,0.01)) +
scale_y_continuous(expand=c(0,0.01)) +
theme_bw() +
theme( legend.title=element_blank())
dev.off()
# ensemble models: random forest
rf <- randomForest(outcome ~ borrower_score + payment_inc_ratio,
data=loan3000)
rf
## Figure 6-6: error rate of random forest
png(filename=file.path(PSDS_PATH, 'figures', 'psds_0606.png'), width = 5, height=4, units='in', res=300)
error_df = data.frame(error_rate = rf$err.rate[,'OOB'],
num_trees = 1:rf$ntree)
ggplot(error_df, aes(x=num_trees, y=error_rate)) +
geom_line()  +
theme_bw()
dev.off()
## Figure 6-7: plot of random forest predictions
png(filename=file.path(PSDS_PATH, 'figures', 'psds_0607.png'),  width = 5, height=4, units='in', res=300)
pred <- predict(rf, prob=TRUE)
rf_df <- cbind(loan3000, pred = pred)
ggplot(data=rf_df, aes(x=borrower_score, y=payment_inc_ratio,
shape=pred, color=pred)) +
geom_point(alpha=.6, size=2) +
scale_shape_manual( values=c( 46, 4)) +
scale_x_continuous(expand=c(0,0)) +
scale_y_continuous(expand=c(0,0), lim=c(0, 20)) +
theme_bw()
dev.off()
# A nice plot showing a gradient of predictions but not as illustrative as the prior plot
## not in book
png(filename=file.path(PSDS_PATH, 'figures', 'psds_rf_gradient.png'),  width = 5, height=4, units='in', res=300)
ggplot(data=rf_df, aes(x=borrower_score, y=payment_inc_ratio, color=prob_default)) +
geom_point(alpha=.6) +
scale_color_gradient2(low='blue', mid='white', high='red', midpoint=.5) +
scale_x_continuous(expand=c(0,0)) +
scale_y_continuous(expand=c(0,0), lim=c(0, 20)) +
theme(legend.position='bottom') +
geom_line(data=lda_df0, col='green', size=2, alpha=.8)
# ensemble models: random forest
rf <- randomForest(outcome ~ borrower_score + payment_inc_ratio,
data=loan3000)
rf
## Figure 6-6: error rate of random forest
png(filename=file.path(PSDS_PATH, 'figures', 'psds_0606.png'), width = 5, height=4, units='in', res=300)
error_df = data.frame(error_rate = rf$err.rate[,'OOB'],
num_trees = 1:rf$ntree)
ggplot(error_df, aes(x=num_trees, y=error_rate)) +
geom_line()  +
theme_bw()
dev.off()
## Figure 6-7: plot of random forest predictions
png(filename=file.path(PSDS_PATH, 'figures', 'psds_0607.png'),  width = 5, height=4, units='in', res=300)
pred <- predict(rf, prob=TRUE)
rf_df <- cbind(loan3000, pred = pred)
ggplot(data=rf_df, aes(x=borrower_score, y=payment_inc_ratio,
shape=pred, color=pred)) +
geom_point(alpha=.6, size=2) +
scale_shape_manual( values=c( 46, 4)) +
scale_x_continuous(expand=c(0,0)) +
scale_y_continuous(expand=c(0,0), lim=c(0, 20)) +
theme_bw()
dev.off()
## Figure 6-8: Variable importance plot for random forest
png(filename=file.path(PSDS_PATH, 'figures', 'psds_0608.png'),  width = 4, height=6, units='in', res=300)
ggplot(imp) +
geom_point(aes(y=Predictor, x=Importance), size=2, stat="identity") +
facet_wrap(~Type, ncol=1, scales="free_x") +
theme(
panel.grid.major.x = element_blank() ,
panel.grid.major.y = element_line(linetype=3, color="darkgray") ) +
theme_bw()
# ensemble models: xgboost
predictors <- data.matrix(loan3000[, c('borrower_score', 'payment_inc_ratio')])
label <- as.numeric(loan3000[,'outcome'])-1
xgb <- xgboost(data=predictors, label=label, objective = "binary:logistic",
params=list(subsample=.63, eta=0.1), nrounds=100)
pred <- predict(xgb, newdata=predictors)
xgb_df <- cbind(loan3000, pred_default=pred>.5, prob_default=pred)
## Figure 6-9: prediction from xgboost
png(filename=file.path(PSDS_PATH, 'figures', 'psds_0609.png'), width = 5, height=4, units='in', res=300)
ggplot(data=xgb_df, aes(x=borrower_score, y=payment_inc_ratio,
color=pred_default, shape=pred_default)) +
geom_point(alpha=.6, size=2) +
scale_shape_manual( values=c( 46, 4)) +
scale_x_continuous(expand=c(.03, 0)) +
scale_y_continuous(expand=c(0,0), lim=c(0, 20)) +
theme_bw()
dev.off()
## Create a test and training set and compare the learning rates under different hyperparameter choices
seed <- 400820
predictors <- data.matrix(loan_data[,-which(names(loan_data) %in% 'outcome')])
label <- as.numeric(loan_data$outcome)-1
test_idx <- sample(nrow(loan_data), 10000)
xgb_default <- xgboost(data=predictors[-test_idx,], label=label[-test_idx],
objective = "binary:logistic", nrounds=250, verbose=0)
pred_default <- predict(xgb_default, predictors[test_idx,])
error_default <- abs(label[test_idx] - pred_default) > 0.5
xgb_default$evaluation_log[250,]
mean(error_default)
xgb_penalty <- xgboost(data=predictors[-test_idx,],
label=label[-test_idx],
params=list(eta=.1, subsample=.63, lambda=1000),
objective = "binary:logistic", nrounds=250, verbose=0)
pred_penalty <- predict(xgb_penalty, predictors[test_idx,])
error_penalty <- abs(label[test_idx] - pred_penalty) > 0.5
xgb_penalty$evaluation_log[250,]
mean(error_penalty)
error_default <- rep(0, 250)
error_penalty <- rep(0, 250)
for(i in 1:250)
{
pred_default <- predict(xgb_default, predictors[test_idx,], ntreelimit = i)
error_default[i] <- mean(abs(label[test_idx] - pred_default) > 0.5)
pred_penalty <- predict(xgb_penalty, predictors[test_idx,], ntreelimit = i)
error_penalty[i] <- mean(abs(label[test_idx] - pred_penalty) > 0.5)
}
errors <- rbind(xgb_default$evaluation_log,
xgb_penalty$evaluation_log,
data.frame(iter=1:250, train_error=error_default),
data.frame(iter=1:250, train_error=error_penalty))
errors$type <- rep(c('default train', 'penalty train',
'default test', 'penalty test'), rep(250, 4))
## Figure 6-10: learning rates for different choices of hyperparameters
png(filename=file.path(PSDS_PATH, 'figures', 'psds_0610.png'), width = 6, height=4, units='in', res=300)
ggplot(errors, aes(x=iter, y=train_error, group=type)) +
geom_line(aes(linetype=type, color=type), size=1) +
scale_linetype_manual(values=c('solid', 'dashed', 'dotted', 'longdash')) +
theme_bw() +
theme(legend.key.width = unit(1.5,"cm")) +
labs(x="Iterations", y="Error") +
guides(colour = guide_legend(override.aes = list(size=1)))
dev.off()
## Cross validation
N <- nrow(loan_data)
fold_number <- sample(1:5, N, replace = TRUE)
params <- data.frame(eta = rep(c(.1, .5, .9), 3),
max_depth = rep(c(3, 6, 12), rep(3,3)))
rf_list <- vector('list', 9)
error <- matrix(0, nrow=9, ncol=5)
for(i in 1:nrow(params)){
for(k in 1:5){
cat('Fold', k, 'for model', i, '\n')
fold_idx <- (1:N)[fold_number == k]
xgb <- xgboost(data=predictors[-fold_idx,], label=label[-fold_idx],
params = list(eta = params[i, 'eta'],
max_depth = params[i, 'max_depth']),
objective = "binary:logistic", nrounds=100, verbose=0)
pred <- predict(xgb, predictors[fold_idx,])
error[i, k] <- mean(abs(label[fold_idx] - pred) >= 0.5)
}
}
avg_error <- 100 * round(rowMeans(error), 4)
cbind(params, avg_error)
knitr::opts_chunk$set(echo = TRUE)
# packages needed for chapter 7
library(dplyr)
library(tidyr)
library(ggplot2)
library(ascii)
library(lubridate)
library(ellipse)
install.packages("ellipse")
# packages needed for chapter 7
library(dplyr)
library(tidyr)
library(ggplot2)
library(ascii)
library(lubridate)
library(ellipse)
library(mclust)
library(cluster)
## PCA for oil data
oil_px = as.data.frame(scale(oil_px, scale=FALSE))
# Import the datasets needed for chapter 7
PSDS_PATH <- file.path('C:/Users/fabia/Desktop', 'psds_data')
## Import datasets needed for chapter 7
sp500_px <- read.csv(file.path(PSDS_PATH, 'data', 'sp500_px.csv'), row.names = 1)
sp500_sym <- read.csv(file.path(PSDS_PATH, 'data', 'sp500_sym.csv'), stringsAsFactors = FALSE)
loan_data <- read.csv(file.path(PSDS_PATH, 'data', 'loan_data.csv'))
loan_data$outcome <- ordered(loan_data$outcome, levels=c('paid off', 'default'))
## PCA for oil data
oil_px = as.data.frame(scale(oil_px, scale=FALSE))
## PCA for oil data
#oil_px = as.data.frame(scale(oil_px, scale=FALSE))
oil_px <- sp500_px[, c('CVX', 'XOM')]
pca <- princomp(oil_px)
pca$loadings
## Figure 7-1: principal components for oil stock data
png(filename=file.path(PSDS_PATH, 'figures', 'psds_0701.png'), width = 4, height=4, units='in', res=300)
loadings <- pca$loadings
ggplot(data=oil_px, aes(x=CVX, y=XOM)) +
geom_point(alpha=.3) +
scale_shape_manual(values=c(46)) +
stat_ellipse(type='norm', level=.99, color='grey25') +
geom_abline(intercept = 0, slope = loadings[2,1]/loadings[1,1], color='grey25', linetype=2) +
geom_abline(intercept = 0, slope = loadings[2,2]/loadings[1,2],  color='grey25', linetype=2) +
scale_x_continuous(expand=c(0,0), lim=c(-3, 3)) +
scale_y_continuous(expand=c(0,0), lim=c(-3, 3)) +
theme_bw()
dev.off()
## Figure 7-2: screeplot
png(filename=file.path(PSDS_PATH, 'figures', 'psds_0702.png'), width = 4, height=4, units='in', res=300)
syms <- c( 'AAPL', 'MSFT', 'CSCO', 'INTC', 'CVX', 'XOM', 'SLB', 'COP',
'JPM', 'WFC', 'USB', 'AXP', 'WMT', 'TGT', 'HD', 'COST')
top_cons <- sp500_px[row.names(sp500_px)>='2011-01-01', syms]
sp_pca <- princomp(top_cons)
par(mar=c(6,3,0,0)+.1, las=2)
screeplot(sp_pca, main='')
dev.off()
## Loadings for stock data
loadings = sp_pca$loadings[,1:5]
loadings <- as.data.frame(loadings)
loadings$Symbol <- row.names(loadings)
loadings <- gather(loadings, "Component", "Weight", -Symbol)
head(loadings)
## Figure 7-3: Plot of component loadings
png(filename=file.path(PSDS_PATH, 'figures', 'psds_0703.png'), width = 4, height=4, units='in', res=300)
loadings$Color = loadings$Weight > 0
ggplot(loadings, aes(x=Symbol, y=Weight, fill=Color)) +
geom_bar(stat='identity', position = "identity", width=.75) +
facet_grid(Component ~ ., scales='free_y') +
guides(fill=FALSE)  +
ylab('Component Loading') +
theme_bw() +
theme(axis.title.x = element_blank(),
axis.text.x  = element_text(angle=90, vjust=0.5))
dev.off()
## K-means chapter
set.seed(1010103)
df <- sp500_px[row.names(sp500_px)>='2011-01-01', c('XOM', 'CVX')]
km <- kmeans(df, centers=4, nstart=1)
df$cluster <- factor(km$cluster)
head(df)
centers <- data.frame(cluster=factor(1:4), km$centers)
centers
## Figure 7-4: K-means clusters for two stocks
png(filename=file.path(PSDS_PATH, 'figures', 'psds_0704.png'), width = 4, height=3, units='in', res=300)
ggplot(data=df, aes(x=XOM, y=CVX, color=cluster, shape=cluster)) +
geom_point(alpha=.3) +
scale_shape_manual(values = 1:4,
guide = guide_legend(override.aes=aes(size=1))) +
geom_point(data=centers,  aes(x=XOM, y=CVX), size=2, stroke=2)  +
theme_bw() +
scale_x_continuous(expand=c(0,0), lim=c(-2, 2)) +
scale_y_continuous(expand=c(0,0), lim=c(-2.5, 2.5))
dev.off()
## cluster means algorithm
syms <- c( 'AAPL', 'MSFT', 'CSCO', 'INTC', 'CVX', 'XOM', 'SLB', 'COP',
'JPM', 'WFC', 'USB', 'AXP', 'WMT', 'TGT', 'HD', 'COST')
df <- sp500_px[row.names(sp500_px)>='2011-01-01', syms]
set.seed(10010)
km <- kmeans(df, centers=5, nstart=10)
km$size
centers <- km$centers
#centers <- scale(scale(centers, center=FALSE, scale=1/attr(df, 'scaled:scale')),
#                 center=-attr(df, 'scaled:center'), scale=FALSE)
## Figure 7-5 interpreting the clusters
centers <- as.data.frame(t(centers))
names(centers) <- paste("Cluster", 1:5)
centers$Symbol <- row.names(centers)
centers <- gather(centers, "Cluster", "Mean", -Symbol)
png(filename=file.path(PSDS_PATH, 'figures', 'psds_0705.png'), width = 4, height=5, units='in', res=300)
centers$Color = centers$Mean > 0
ggplot(centers, aes(x=Symbol, y=Mean, fill=Color)) +
geom_bar(stat='identity', position = "identity", width=.75) +
facet_grid(Cluster ~ ., scales='free_y') +
guides(fill=FALSE)  +
ylab('Component Loading') +
theme_bw() +
theme(axis.title.x = element_blank(),
axis.text.x  = element_text(angle=90, vjust=0.5))
dev.off()
## Figure 7-6: selecting the number of clusters (elbow plot)
pct_var <- data.frame(pct_var = 0,
num_clusters=2:14)
totalss <- kmeans(df, centers=14, nstart=50, iter.max = 100)$totss
for(i in 2:14){
pct_var[i-1, 'pct_var'] <- kmeans(df, centers=i, nstart=50, iter.max = 100)$betweenss/totalss
}
png(filename=file.path(PSDS_PATH, 'figures', 'psds_0706.png'), width = 4, height=3, units='in', res=300)
ggplot(pct_var, aes(x=num_clusters, y=pct_var)) +
geom_line() +
geom_point() +
labs(y='% Variance Explained', x='Number of Clusters') +
scale_x_continuous(breaks=seq(2, 14, by=2))   +
theme_bw()
dev.off()
## hclust chapter
syms1 <- c('GOOGL', 'AMZN', 'AAPL', 'MSFT', 'CSCO', 'INTC', 'CVX',
'XOM', 'SLB', 'COP', 'JPM', 'WFC', 'USB', 'AXP',
'WMT', 'TGT', 'HD', 'COST')
df <- sp500_px[row.names(sp500_px)>='2011-01-01', syms1]
d <- dist(t(df))
hcl <- hclust(d)
## Figure 7-7: dendograme of stock data
png(filename=file.path(PSDS_PATH, 'figures', 'psds_0707.png'), width = 4, height=4, units='in', res=300)
par(cex=.75, mar=c(0, 5, 0, 0)+.1)
plot(hcl, ylab='distance', xlab='', sub='', main='')
dev.off()
## Figure 7-8: comparison of the different measuresof dissimilarity
cluster_fun <- function(df, method)
{
d <- dist(df)
hcl <- hclust(d, method=method)
tree <- cutree(hcl, k=4)
df$cluster <- factor(tree)
df$method <- method
return(df)
}
df0 <- sp500_px[row.names(sp500_px)>='2011-01-01', c('XOM', 'CVX')]
df <- rbind(cluster_fun(df0, method='single'),
cluster_fun(df0, method='average'),
cluster_fun(df0, method='complete'),
cluster_fun(df0, method='ward.D'))
df$method <- ordered(df$method, c('single', 'average', 'complete', 'ward.D'))
png(filename=file.path(PSDS_PATH, 'figures', 'psds_0708.png'), width = 5.5, height=4, units='in', res=300)
ggplot(data=df, aes(x=XOM, y=CVX, color=cluster, shape=cluster)) +
geom_point(alpha=.3) +
scale_shape_manual(values = c(46, 3, 1,  4),
guide = guide_legend(override.aes=aes(size=2))) +
facet_wrap( ~ method) +
theme_bw()
dev.off()
# Model-based clusting
# Multivariate normal
mu <- c(.5, -.5)
sigma <- matrix(c(1, 1, 1, 2), nrow=2)
prob <- c(.5, .75, .95, .99) ## or whatever you want
names(prob) <- prob ## to get id column in result
x <- NULL
for (p in prob){
x <- rbind(x,  ellipse(x=sigma, centre=mu, level=p))
}
df <- data.frame(x, prob=factor(rep(prob, rep(100, length(prob)))))
names(df) <- c("X", "Y", "Prob")
## Figure 7-9: Multivariate normal ellipses
dfmu <- data.frame(X=mu[1], Y=mu[2])
png(filename=file.path(PSDS_PATH, 'figures', 'psds_0709.png'), width = 4, height=4, units='in', res=300)
ggplot(df, aes(X, Y)) +
geom_path(aes(linetype=Prob)) +
geom_point(data=dfmu, aes(X, Y), size=3) +
theme_bw()
dev.off()
## Figure 7-10 mclust applied XOM and CVX
df <- sp500_px[row.names(sp500_px)>='2011-01-01', c('XOM', 'CVX')]
mcl <- Mclust(df)
summary(mcl)
cluster <- factor(predict(mcl)$classification)
png(filename=file.path(PSDS_PATH, 'figures', 'psds_0710.png'), width = 5, height=4, units='in', res=300)
ggplot(data=df, aes(x=XOM, y=CVX, color=cluster, shape=cluster)) +
geom_point(alpha=.8) +
theme_bw() +
scale_shape_manual(values = c(46, 3),
guide = guide_legend(override.aes=aes(size=2)))
dev.off()
summary(mcl, parameters=TRUE)$mean
summary(mcl, parameters=TRUE)$variance
## Figure 7-11: BIC scores for the different models fit by mclust
png(filename=file.path(PSDS_PATH, 'figures', 'psds_0711.png'), width = 4, height=4, units='in', res=300)
par(mar=c(4, 5, 0, 0)+.1)
plot(mcl, what='BIC', ask=FALSE, cex=.75)
dev.off()
#
# Scaling chapter
defaults <- loan_data[loan_data$outcome=='default',]
df <- defaults[, c('loan_amnt', 'annual_inc', 'revol_bal', 'open_acc', 'dti', 'revol_util')]
km <- kmeans(df, centers=4, nstart=10)
centers <- data.frame(size=km$size, km$centers)
round(centers, digits=2)
df0 <- scale(df)
km0 <- kmeans(df0, centers=4, nstart=10)
centers0 <- scale(km0$centers, center=FALSE, scale=1/attr(df0, 'scaled:scale'))
centers0 <- scale(centers0, center=-attr(df0, 'scaled:center'), scale=FALSE)
centers0 <- data.frame(size=km0$size, centers0)
round(centers0, digits=2)
km <- kmeans(df, centers=4, nstart=10)
centers <- data.frame(size=km$size, km$centers)
round(centers, digits=2)
## Figure 7-12: screeplot for data with dominant variables
syms <- c('GOOGL', 'AMZN', 'AAPL', 'MSFT', 'CSCO', 'INTC', 'CVX', 'XOM',
'SLB', 'COP', 'JPM', 'WFC', 'USB', 'AXP', 'WMT', 'TGT', 'HD', 'COST')
top_15 <- sp500_px[row.names(sp500_px)>='2011-01-01', syms]
sp_pca1 <- princomp(top_15)
png(filename=file.path(PSDS_PATH, 'figures', 'psds_0712.png'), width = 4, height=4, units='in', res=300)
par(mar=c(6,3,0,0)+.1, las=2)
screeplot(sp_pca1, main='')
dev.off()
round(sp_pca1$loadings[,1:2], 3)
## Figure 7-13: Categorical data and Gower's distance
x <- loan_data[1:5, c('dti', 'payment_inc_ratio', 'home_', 'purpose_')]
x
daisy(x, metric='gower')
set.seed(301)
df <- loan_data[sample(nrow(loan_data), 250),
c('dti', 'payment_inc_ratio', 'home_', 'purpose_')]
d = daisy(df, metric='gower')
hcl <- hclust(d)
dnd <- as.dendrogram(hcl)
png(filename=file.path(PSDS_PATH, 'figures', 'psds_0713.png'), width = 4, height=4, units='in', res=300)
par(mar=c(0,5,0,0)+.1)
plot(dnd, leaflab='none', ylab='distance')
dev.off()
dnd_cut <- cut(dnd, h=.5)
df[labels(dnd_cut$lower[[1]]),]
## Problems in clustering with mixed data types
df <- model.matrix(~ -1 + dti + payment_inc_ratio + home_ + pub_rec_zero, data=defaults)
df0 <- scale(df)
km0 <- kmeans(df0, centers=4, nstart=10)
centers0 <- scale(km0$centers, center=FALSE, scale=1/attr(df0, 'scaled:scale'))
round(scale(centers0, center=-attr(df0, 'scaled:center'), scale=FALSE), 2)
